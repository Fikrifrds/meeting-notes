# Meeting Notes App Environment Configuration
# Copy this file to .env and configure your settings

# =============================================================================
# AI PROVIDER CONFIGURATION
# =============================================================================

# Choose your AI provider for meeting minutes generation:
# - Use OpenAI for best quality (requires API key)
# - Use Ollama for complete privacy (runs locally)

# -----------------------------------------------------------------------------
# OPENAI CONFIGURATION (Cloud AI - Best Quality)
# -----------------------------------------------------------------------------
# OpenAI API Key (get from https://platform.openai.com/api-keys)
OPENAI_API_KEY=sk-your-api-key-here

# OpenAI model to use (default: gpt-4.1 for cost efficiency)
OPENAI_MODEL=gpt-4.1

# Maximum tokens for OpenAI response (default: 2000)
OPENAI_MAX_TOKENS=2000

# Temperature for OpenAI response (0.0-1.0, default: 0.3 for consistent output)
OPENAI_TEMPERATURE=0.3

# -----------------------------------------------------------------------------
# OLLAMA CONFIGURATION (Local AI - Privacy Focused)
# -----------------------------------------------------------------------------
# Ollama host URL (default: http://localhost:11434)
OLLAMA_HOST=http://localhost:11434

# Ollama model to use for meeting minutes generation
# Popular options:
# - gemma3:4b (very fast, smaller model - current default)
# - llama3.1:8b (good balance of quality and speed)
# - llama3.1:7b (faster, slightly lower quality)
# - mistral:7b (alternative option)
# - codellama:7b (good for technical meetings)
OLLAMA_MODEL=gemma3:4b


# =============================================================================
# SETUP INSTRUCTIONS
# =============================================================================

# FOR OPENAI (CLOUD AI):
# 1. Get API key from https://platform.openai.com/api-keys
# 2. Add your OPENAI_API_KEY to your .env file
# 3. Optionally configure model, tokens, and temperature
# 4. The app will use OpenAI by default

# FOR OLLAMA (LOCAL AI):
# 1. Install Ollama: https://ollama.ai/
# 2. Pull the model: ollama pull gemma3:4b
# 3. Start Ollama: ollama serve
# 4. Comment out OPENAI_API_KEY and uncomment OLLAMA settings

# =============================================================================
# PRIVACY CONSIDERATIONS
# =============================================================================

# OPENAI (Cloud AI):
# ✅ Best quality meeting minutes
# ✅ Fast and reliable processing
# ✅ No local hardware requirements
# ❌ Requires API key and incurs costs
# ⚠️ Transcript text sent to OpenAI for processing

# OLLAMA (Local AI):
# ✅ Complete privacy - transcript never leaves your device
# ✅ No internet required for AI processing
# ✅ No API costs
# ❌ Requires local installation
# ❌ Lower quality compared to OpenAI